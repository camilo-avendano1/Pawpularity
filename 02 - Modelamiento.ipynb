{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "\n",
    "trainpt = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibles: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Memoria GPU configurada para crecimiento dinámico.\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6685683657292318830\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5713690624\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10282146362433573378\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "print(\"GPUs disponibles:\", tf.config.list_physical_devices('GPU'))\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Memoria GPU configurada para crecimiento dinámico.\")\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepara los datos para que sea más fácil acceder a las imágenes utilizando las rutas generadas.\n",
    "def train_id_to_path(x):\n",
    "    return 'train/' + x + \".jpg\"\n",
    "def test_id_to_path(x):\n",
    "    return 'test/' + x + \".jpg\"\n",
    "traint = pd.read_csv('train.csv')\n",
    "train11=traint[[\"Id\",\"Pawpularity\"]]\n",
    "testt = pd.read_csv('test.csv')\n",
    "test11 = testt[[\"Id\"]] \n",
    "train11[\"img_path\"] = train11[\"Id\"].apply(train_id_to_path)\n",
    "test11[\"img_path\"] = test11[\"Id\"].apply(test_id_to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La función devuelve un tensor que representa la imagen\n",
    "# Normalizada (valores entre 0 y 1).\n",
    "# Redimensionada a 128x128 píxeles.\n",
    "# Con 3 canales de color (RGB).\n",
    "image_height = 128\n",
    "image_width = 128\n",
    "def path_to_eagertensor(image_path):\n",
    "    raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(raw, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, (image_height, image_width))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 9912\n",
      "<class 'numpy.ndarray'> (9912, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Organizar datos en un formato estándar: Al convertir \n",
    "# la lista de tensores en un array de NumPy,\n",
    "# se asegura que las imágenes se puedan procesar \n",
    "# eficientemente en lotes para el entrenamiento del modelo.\n",
    "\n",
    "X1 = []\n",
    "for img in train11['img_path']:\n",
    "    new_img_tensor = path_to_eagertensor(img)\n",
    "    X1.append(new_img_tensor)\n",
    "    \n",
    "print(type(X1),len(X1))\n",
    "X1 = np.array(X1)\n",
    "print(type(X1),X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 8\n",
      "<class 'numpy.ndarray'> (8, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#realiuzamos lo mismo para el conjunto de test\n",
    "X1_sub = []\n",
    "for img in test11['img_path']:\n",
    "    new_img_tensor = path_to_eagertensor(img)\n",
    "    X1_sub.append(new_img_tensor)\n",
    "    \n",
    "print(type(X1_sub),len(X1_sub))\n",
    "X1_sub = np.array(X1_sub)\n",
    "print(type(X1_sub),X1_sub.shape)\n",
    "y1=train11[\"Pawpularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7929, 128, 128, 3) (1983, 128, 128, 3) (7929,) (1983,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(image_height,image_width,3))\n",
    "x = inputs\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2),padding='valid',activation = 'relu')(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same',activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same',activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same',activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same',activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same',activation = 'relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 61, 61, 16)        2368      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 31, 31, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 31, 31, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,480,865\n",
      "Trainable params: 4,480,033\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='mse', metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator es una clase de Keras que permite realizar transformaciones\n",
    "# en las imágenes para crear nuevas versiones (aumentación) en tiempo real durante\n",
    "# el entrenamiento. Esto es útil para evitar el sobreajuste y aumentar la diversidad\n",
    "# de los datos de entrenamiento.\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range = 15, \n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.1,\n",
    "    horizontal_flip = True, \n",
    "    fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "248/248 [==============================] - 25s 78ms/step - loss: 507.6636 - rmse: 22.5314 - mae: 16.8393 - mape: 81.5462 - val_loss: 460.2799 - val_rmse: 21.4541 - val_mae: 16.3842 - val_mape: 79.9077\n",
      "Epoch 2/3\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 480.3781 - rmse: 21.9175 - mae: 16.4458 - mape: 80.5542 - val_loss: 474.0730 - val_rmse: 21.7732 - val_mae: 15.2639 - val_mape: 65.2966\n",
      "Epoch 3/3\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 474.3529 - rmse: 21.7796 - mae: 16.2891 - mape: 79.8476 - val_loss: 453.2065 - val_rmse: 21.2886 - val_mae: 15.1357 - val_mape: 67.5263\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data_augmentation.flow(x_train,y_train,batch_size=32),\n",
    "    validation_data = (x_test,y_test),\n",
    "    epochs = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el objeto de búsqueda con un objetivo explícito\n",
    "\n",
    "def build_model(hp):\n",
    "    inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
    "    x = inputs\n",
    "\n",
    "    # Elegir dinámicamente el tamaño del kernel\n",
    "    kernel_size = hp.Choice('kernel_size', values=[3, 5, 7])  # Solo enteros\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_1', values=[16, 32, 64]),\n",
    "        kernel_size=(kernel_size, kernel_size),  # Crear la tupla aquí\n",
    "        strides=(2, 2),\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_2', values=[32, 64, 128]),\n",
    "        kernel_size=(kernel_size, kernel_size),\n",
    "        strides=(2, 2),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_3', values=[64, 128, 256]),\n",
    "        kernel_size=(kernel_size, kernel_size),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Choice('dense_units', values=[256, 512, 1024]),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('dropout_rate', values=[0.3, 0.5, 0.7]))(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 Complete [00h 01m 29s]\n",
      "val_rmse: 21.58303451538086\n",
      "\n",
      "Best val_rmse So Far: 20.392410278320312\n",
      "Total elapsed time: 10h 15m 59s\n",
      "Mejores Hiperparámetros: {'kernel_size': 5, 'filters_layer_1': 32, 'filters_layer_2': 64, 'filters_layer_3': 64, 'dense_units': 1024, 'dropout_rate': 0.5, 'learning_rate': 0.0001, 'tuner/epochs': 4, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear el objeto de búsqueda\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=kt.Objective(\"val_rmse\", direction=\"min\"),  # Especificar la métrica personalizada\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir',\n",
    "    project_name='pawpularity_optimization'\n",
    ")\n",
    "\n",
    "# Llamada para buscar mejores hiperparámetros\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Mejor configuración encontrada\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Mejores Hiperparámetros:\", best_hps.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v2(hp):\n",
    "    inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
    "    x = inputs\n",
    "\n",
    "    # Primera capa convolucional\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_1', values=[32, 64, 128]),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_2', values=[64, 128, 256]),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Tercera capa convolucional\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters=hp.Choice('filters_layer_3', values=[128, 256, 512]),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Regularización y capa densa\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        units=hp.Choice('dense_units', values=[128, 256, 512]),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(hp.Choice('l2_rate', values=[1e-4, 1e-3]))\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(hp.Choice('dropout_rate', values=[0.1, 0.3, 0.5]))(x)\n",
    "\n",
    "    # Salida con activación sigmoide\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    output = output * 100  # Escalar a rango 0-100\n",
    "\n",
    "    # Compilar modelo\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 39s]\n",
      "val_rmse: 43.44029235839844\n",
      "\n",
      "Best val_rmse So Far: 20.930692672729492\n",
      "Total elapsed time: 00h 31m 18s\n",
      "Mejores Hiperparámetros: {'filters_layer_1': 32, 'filters_layer_2': 256, 'filters_layer_3': 128, 'dense_units': 128, 'l2_rate': 0.001, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'tuner/epochs': 4, 'tuner/initial_epoch': 2, 'tuner/bracket': 2, 'tuner/round': 1, 'tuner/trial_id': '0000'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear el objeto de búsqueda de hiperparámetros\n",
    "tuner = kt.Hyperband(\n",
    "    build_model_v2,\n",
    "    objective=kt.Objective(\"val_rmse\", direction=\"min\"),  # Especificar la métrica personalizada\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir_v2',\n",
    "    project_name='pawpularity_optimization_v2'\n",
    ")\n",
    "\n",
    "# Ejecutar la búsqueda de los mejores hiperparámetros\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Mostrar la mejor configuración encontrada\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Mejores Hiperparámetros:\", best_hps.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progreso Inicial:\n",
    "\n",
    "El modelo está aprendiendo, como lo muestra la reducción significativa del loss, mae, y rmse entre las épocas 1 y 2.\n",
    "Estabilidad:\n",
    "\n",
    "La estabilidad de las métricas (val_loss y val_rmse) entre las épocas 2 y 3 indica que el modelo ha alcanzado un punto de convergencia, aunque no óptimo.\n",
    "Error Relativo Alto:\n",
    "\n",
    "El mape y el rmse sugieren que el modelo aún no predice con alta precisión. Un rmse cercano a 21 unidades sigue siendo significativo, dado que la escala de \"Pawpularity\" es de 0 a 100.\n",
    "Posible Sobreajuste:\n",
    "\n",
    "El incremento en val_loss y val_rmse en la tercera época podría ser un signo de sobreajuste temprano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2onehot_4(labels):\n",
    "    result = []\n",
    "    for label in labels:\n",
    "#         print(label)\n",
    "        if label == '0':\n",
    "#             print(\"label 1\")\n",
    "            result.append([1, 0, 0, 0])\n",
    "        elif label == '1':\n",
    "            result.append([0,1,0,0])\n",
    "        elif label == '2':\n",
    "            result.append([0,0,1,0])\n",
    "        else:\n",
    "#             print(\"label 0\")\n",
    "            result.append([0,0,0,1])\n",
    "    return np.array(result)\n",
    "x_train_array = np.array(x_train)\n",
    "x_test_array = np.array(x_test)\n",
    "y_train_onehot = convert2onehot_4(y_train)\n",
    "y_test_onehot = convert2onehot_4(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = tf.keras.Input(shape=(image_height,image_width,3))\n",
    "x1 = inputs1\n",
    "\n",
    "x1 = tf.keras.layers.Conv2D(filters = 16, kernel_size = (7,7), strides = (2,2),padding='valid',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2,2), padding='same',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "\n",
    "x1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding='same',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "x1 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "x1 = tf.keras.layers.Dropout(0.25)(x1)\n",
    "\n",
    "x1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "x1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same',activation = 'relu')(x1)\n",
    "x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "x1 = tf.keras.layers.Dropout(0.25)(x1)\n",
    "\n",
    "x1 = tf.keras.layers.Flatten()(x1)\n",
    "x1 = tf.keras.layers.Dense(512, activation = \"relu\")(x1)\n",
    "x1 = tf.keras.layers.Dropout(0.5)(x1)\n",
    "\n",
    "output1 = tf.keras.layers.Dense(4)(x1)\n",
    "\n",
    "model1 = tf.keras.Model(inputs = inputs1, outputs = output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7929, 128, 128, 3) (7929, 4) (1983, 128, 128, 3) (1983, 4)\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='Adam', loss='mse', metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"), \"mae\", \"mape\"]) \n",
    "print(x_train_array.shape, y_train_onehot.shape,x_test_array.shape, y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 61, 61, 16)        2368      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 31, 31, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 31, 31, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 31, 31, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,482,404\n",
      "Trainable params: 4,481,572\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "496/496 [==============================] - 8s 14ms/step - loss: 0.2197 - rmse: 0.4687 - mae: 0.1806 - mape: 85701296.0000 - val_loss: 0.1545 - val_rmse: 0.3931 - val_mae: 0.1748 - val_mape: 99758616.0000\n",
      "Epoch 2/3\n",
      "496/496 [==============================] - 6s 12ms/step - loss: 0.0163 - rmse: 0.1278 - mae: 0.0557 - mape: 4506649.5000 - val_loss: 0.0656 - val_rmse: 0.2561 - val_mae: 0.0723 - val_mape: 31532024.0000\n",
      "Epoch 3/3\n",
      "496/496 [==============================] - 7s 13ms/step - loss: 0.0061 - rmse: 0.0779 - mae: 0.0330 - mape: 1971696.5000 - val_loss: 0.0456 - val_rmse: 0.2135 - val_mae: 0.0403 - val_mape: 25925312.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ac1a1d8d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train_array, y_train_onehot, batch_size=16, epochs=3, validation_data=(x_test_array, y_test_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "(8, 128, 128, 3) <class 'numpy.ndarray'>\n",
      "(8, 1) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = model.predict(X1_sub)\n",
    "print(X1_sub.shape, type(X1_sub))\n",
    "print(cnn_pred.shape, type(cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = pd.DataFrame()\n",
    "cnn['Id'] = test11['Id']\n",
    "cnn['Pawpularity'] = cnn_pred\n",
    "cnn.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>37.240929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>37.549671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>37.808235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>37.142014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>38.097736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b03f7041962238a7c9d6537e22f9b017</td>\n",
       "      <td>37.510044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c978013571258ed6d4637f6e8cc9d6a3</td>\n",
       "      <td>37.887524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e0de453c1bffc20c22b072b34b54e50f</td>\n",
       "      <td>37.140045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    37.240929\n",
       "1  43a2262d7738e3d420d453815151079e    37.549671\n",
       "2  4e429cead1848a298432a0acad014c9d    37.808235\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    37.142014\n",
       "4  8f49844c382931444e68dffbe20228f4    38.097736\n",
       "5  b03f7041962238a7c9d6537e22f9b017    37.510044\n",
       "6  c978013571258ed6d4637f6e8cc9d6a3    37.887524\n",
       "7  e0de453c1bffc20c22b072b34b54e50f    37.140045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "(8, 128, 128, 3) <class 'numpy.ndarray'>\n",
      "(8, 4) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "cnn_pred1 = model1.predict(X1_sub)\n",
    "print(X1_sub.shape, type(X1_sub))\n",
    "print(cnn_pred1.shape, type(cnn_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.947257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.950817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.957185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.961188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.952846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.948315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.943971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.956783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.000381  0.001802  0.000563  0.947257\n",
       "1  0.000322  0.001794  0.000645  0.950817\n",
       "2  0.000448  0.002077  0.000727  0.957185\n",
       "3  0.000399  0.001804  0.000506  0.961188\n",
       "4  0.000390  0.001895  0.000601  0.952846\n",
       "5  0.000399  0.001937  0.000695  0.948315\n",
       "6  0.000360  0.001661  0.000460  0.943971\n",
       "7  0.000425  0.001906  0.000578  0.956783"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1=pd.DataFrame(cnn_pred1)\n",
    "cnn1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
